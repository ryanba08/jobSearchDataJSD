{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import requests\n","import time\n","from bs4 import BeautifulSoup\n","import csv\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def extract(jobtype,page=1):\n","    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'}\n","    r = requests.get(url=f'https://builtin.com/jobs/remote?search={jobtype}&page={page}',headers=headers)\n","    if r.status_code == 200:\n","        print('success',page)\n","        return r.content\n","    else:\n","        print(f'status code {r.status_code} sorry :( failed on page {page}')\n","    return None"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#extract job info from job cards and return a list of dictionarys with the title description salary and date posted\n","def pull_data(soup):\n","    data = []\n","    job_cards = soup.find_all('div', {'data-id': 'job-card'})\n","    for card in job_cards:\n","\n","        job_info = {'title':'','description':'','salary':'','date_posted':''}\n","        job_info['title'] = card.find('div',{'data-id': 'company-title'}).text\n","        job_info['description'] = card.find('h2').text\n","        job_info['date_posted'] = card.find('span',string=lambda x: any(substring in x for substring in ['Ago','Yesterday'])).text\n","\n","        pay_info = card.find('span', string=lambda x: 'Annually' in x)\n","        if pay_info:\n","            job_info['salary'] = pay_info.text\n","\n","        data.append(job_info)\n","    return data"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["success 1\n"]}],"source":["#find max page number for that jobtype change jobtype to search different types of jobs\n","jobtype = 'data'\n","html = extract(jobtype=jobtype)\n","soup = BeautifulSoup(html, 'html.parser')\n","max_page = soup.find_all('li', class_='mx-xs page-item')[-1].text"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["success 1\n","success 2\n","success 3\n","success 4\n","success 5\n","success 6\n","success 7\n","success 8\n","success 9\n","success 10\n","success 11\n","success 12\n","success 13\n","success 14\n","success 15\n","success 16\n","success 17\n","success 18\n","success 19\n","success 20\n","success 21\n","success 22\n","success 23\n","success 24\n","success 25\n","success 26\n","success 27\n","success 28\n","success 29\n","success 30\n","success 31\n","success 32\n","success 33\n","success 34\n","success 35\n","success 36\n","success 37\n","success 38\n","success 39\n","success 40\n","success 41\n","success 42\n","success 43\n","success 44\n","success 45\n","success 46\n","success 47\n","success 48\n","success 49\n","success 50\n","success 51\n","success 52\n","success 53\n","success 54\n","success 55\n","success 56\n","success 57\n","success 58\n","success 59\n","success 60\n","success 61\n","success 62\n","success 63\n","success 64\n","success 65\n","success 66\n","success 67\n","success 68\n","success 69\n","success 70\n","success 71\n","success 72\n","success 73\n","success 74\n","success 75\n","success 76\n","success 77\n"]}],"source":["#pull data from all pages\n","data = []\n","for i in range(1,int(max_page)+1):\n","    html = extract(jobtype,i)\n","    if html:\n","        soup = BeautifulSoup(html, 'html.parser')\n","        data.append(pull_data(soup))\n","    time.sleep(1)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#get rid of duplicates and merge lists to one\n","finalData = []\n","for page in data:\n","    for item in page:\n","        if item not in finalData:\n","            finalData.append(item)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["headers = finalData[0].keys()\n","with open('builtInData.csv', 'w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=headers)\n","    writer.writeheader()\n","    writer.writerows(finalData)"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":2}
