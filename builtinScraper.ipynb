{"cells":[{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["import requests\n","import time\n","from bs4 import BeautifulSoup\n","import csv\n"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["def extract(jobtype,page=1):\n","    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'}\n","    r = requests.get(url=f'https://builtin.com/jobs/remote?search={jobtype}&page={page}',headers=headers)\n","    if r.status_code == 200:\n","        return r.content\n","    else:\n","        print(f'status code {r.status_code} sorry :(')\n","    return None"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["#extract job info from job cards and return a list of dictionarys with the title description salary date posted employee count and years experience.\n","def pull_data(soup):\n","    data = []\n","    job_cards = soup.find_all('div', {'data-id': 'job-card'})\n","    for card in job_cards:\n","\n","        job_info = {'title':'','description':'','salary':'','date_posted':'','employee_count':'','experience':''}\n","        job_info['title'] = card.find('div',{'data-id': 'company-title'}).text\n","        job_info['description'] = card.find('h2').text\n","        job_info['date_posted'] = card.find('span',string=lambda x: any(substring in x for substring in ['Ago','Yesterday'])).text\n","\n","        pay_info = card.find('span', string=lambda x: 'Annually' in x)\n","        if pay_info:\n","            job_info['salary'] = pay_info.text\n","\n","        employee_count = card.find('span', string=lambda x: 'Employees' in x)\n","        if employee_count:\n","            job_info['employee_count'] = int(employee_count.text.replace(',','').split(' ')[0])\n","        \n","        years_experience = card.find('span', string=lambda x: 'Experience' in x)\n","        if years_experience:\n","            job_info['experience'] = years_experience.text\n","\n","        data.append(job_info)\n","    return data"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["#find max page number for that jobtype change jobtype to search different types of jobs\n","jobtype = 'data'\n","html = extract(jobtype=jobtype)\n","soup = BeautifulSoup(html, 'html.parser')\n","max_page = soup.find_all('li', class_='mx-xs page-item')[-1].text"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["#pull data from all pages\n","data = []\n","for i in range(1,int(max_page)+1):\n","    html = extract(jobtype,i)\n","    soup = BeautifulSoup(html, 'html.parser')\n","    data.append(pull_data(soup))\n","    time.sleep(1)"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["#get rid of duplicates and merge lists to one\n","finalData = []\n","for page in data:\n","    for item in page:\n","        if item not in finalData:\n","            finalData.append(item)"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["headers = finalData[0].keys()\n","with open('builtInData.csv', 'w', newline='') as csv_file:\n","    writer = csv.DictWriter(csv_file, fieldnames=headers)\n","    writer.writeheader()\n","    writer.writerows(finalData)"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":2}
